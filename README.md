# ğŸš€ Projeto de SimulaÃ§Ã£o de Atividades BancÃ¡rias com Kafka, MongoDB e Streamlit

Este projeto simula um pipeline de dados de atividades bancÃ¡rias usando **Apache Kafka** para transmissÃ£o de mensagens, **MongoDB** para armazenamento e **Streamlit** para visualizaÃ§Ã£o e anÃ¡lise em tempo real.

---

## ğŸŒŸ VisÃ£o Geral

O objetivo principal Ã© demonstrar um fluxo de dados em tempo real:

1. **GeraÃ§Ã£o de Dados FictÃ­cios:** Um `Producer` gera transaÃ§Ãµes bancÃ¡rias simuladas (depÃ³sitos, saques, transferÃªncias) com lÃ³gica de saldo.
2. **Streaming de Mensagens:** As transaÃ§Ãµes sÃ£o enviadas para um tÃ³pico Kafka.
3. **Consumo e PersistÃªncia:** Um `Consumer` lÃª as mensagens do Kafka e as persiste em um banco de dados MongoDB.
4. **VisualizaÃ§Ã£o AnalÃ­tica:** O Streamlit se conecta ao MongoDB para exibir informaÃ§Ãµes analÃ­ticas e insights sobre as movimentaÃ§Ãµes bancÃ¡rias, incluindo uma camada de inteligÃªncia artificial com a **API Google Gemini** para perguntas abertas e anÃ¡lise contextual dos dados.

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Apache Kafka:** Plataforma de streaming de eventos distribuÃ­da.
* **MongoDB:** Banco de dados NoSQL para armazenamento das transaÃ§Ãµes.
* **Streamlit:** Framework Python para construÃ§Ã£o rÃ¡pida de aplicaÃ§Ãµes web interativas e dashboards.
* **Google Gemini API:** Modelo de linguagem de grande escala (LLM) para anÃ¡lise conversacional e extraÃ§Ã£o de insights dos dados, integrado ao Streamlit.
* **Python:** Linguagem de programaÃ§Ã£o principal.
* **Docker & Docker Compose:** Para orquestraÃ§Ã£o e execuÃ§Ã£o dos serviÃ§os (Kafka, Zookeeper, MongoDB).

---

## ğŸ”‘ ConfiguraÃ§Ã£o da Google Gemini API

Para utilizar a funcionalidade de "Perguntas com IA" e outras anÃ¡lises do Gemini, vocÃª precisarÃ¡ configurar sua chave de API:

1.  **Obtenha uma Chave de API:** Acesse o [Google AI Studio](https://aistudio.google.com/app/apikey) ou o [Console do Google Cloud](https://console.cloud.google.com/apis/credentials) para gerar sua chave de API para o Gemini.

2.  **Crie um arquivo `.env`:** Na raiz do projeto, crie um arquivo chamado `.env` (se jÃ¡ nÃ£o existir) e adicione sua chave de API no seguinte formato:

    ```
    GENAI_API_KEY="SUA_CHAVE_DE_API_AQUI"
    ```

    Substitua `"SUA_CHAVE_DE_API_AQUI"` pela chave que vocÃª obteve.

    **Importante:** Nunca compartilhe sua chave de API publicamente nem a inclua diretamente no cÃ³digo-fonte ou em repositÃ³rios pÃºblicos. O arquivo `.env` Ã© lido localmente e nÃ£o deve ser versionado (verifique se `*.env` estÃ¡ no seu `.gitignore`).

---

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ docker-compose.yml              # DefiniÃ§Ã£o dos serviÃ§os Docker (Kafka, Zookeeper, MongoDB)
â”œâ”€â”€ Dockerfile                      # Arquivo para criaÃ§Ã£o da imagem Docker do projeto
â”œâ”€â”€ poetry.lock                     # Bloqueio das dependÃªncias do Poetry
â”œâ”€â”€ pyproject.toml                  # DependÃªncias do projeto (utiliza o Poetry)
â”œâ”€â”€ README.md                       # Este arquivo
â”œâ”€â”€ requirements.txt                # DependÃªncias Python (caso nÃ£o use o Poetry)
â””â”€â”€ src/
    â”œâ”€â”€ dashboard_streamlit.py      # AplicaÃ§Ã£o Streamlit para visualizaÃ§Ã£o das transaÃ§Ãµes
    â”œâ”€â”€ kafka_consumer.py           # Script para consumir dados do Kafka e persistir no MongoDB
    â”œâ”€â”€ kafka_producer.py           # Script para gerar e enviar dados para o Kafka
    â”œâ”€â”€ main.py                     # Script principal que executa o producer, consumer e Streamlit
    â”œâ”€â”€ mongodb_connect.py          # MÃ³dulo para conexÃ£o e operaÃ§Ãµes no MongoDB
    â””â”€â”€ test
        â”œâ”€â”€ test_producer.py        # Script para testar a funÃ§Ã£o que gera dados para o Kafka
        â””â”€â”€ verifica_dados_mongo.py # Script para testar e verificar dados no MongoDB
```
---

## ğŸ“Š VisualizaÃ§Ã£o no Streamlit

O aplicativo Streamlit (`dashboard_streamlit.py`) se conecta ao MongoDB e fornece um dashboard interativo onde vocÃª poderÃ¡:

* Ver as Ãºltimas transaÃ§Ãµes.
* Visualizar estatÃ­sticas agregadas (total de depÃ³sitos, saques, etc.).
* Analisar o saldo dos clientes (se implementado no Streamlit).
* Observar o fluxo de dados em tempo real.
* Utilizar uma nova aba de "Perguntas com IA" para obter insights e resumos dos dados atravÃ©s da API Google Gemini, permitindo consultas em linguagem natural sobre o comportamento das transaÃ§Ãµes.
* Receber projeÃ§Ãµes preditivas e anÃ¡lises detalhadas de transaÃ§Ãµes especÃ­ficas, potencializadas pelo raciocÃ­nio do Gemini.

---

## ğŸ–¼ï¸ Dashboard Streamlit

Aqui estÃ£o capturas de telas do dashboard Streamlit:

![Painel 01](docs/images/streamlit_01.png)
![Painel 03](docs/images/streamlit_03.png)
![Painel 04](docs/images/streamlit_04.png)
![Painel 05](docs/images/streamlit_05.png)

---

## ğŸš€ Como Rodar o Projeto

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/felipealvss/kafka_randomfaker.git
cd kafka_randomfaker
```

### 2. Configurar o Ambiente

Recomenda-se usar o **Poetry** para gerenciar as dependÃªncias do projeto:

```bash
poetry install
```

Alternativamente, se preferir usar o `pip`, instale as dependÃªncias listadas no `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 3. Subir os ServiÃ§os com Docker Compose

Este projeto utiliza Docker e Docker Compose para orquestrar os serviÃ§os. Execute o seguinte comando para iniciar o Kafka, Zookeeper e o MongoDB:

```bash
docker-compose up -d
```

Isso irÃ¡ subir os containers com as configuraÃ§Ãµes predefinidas.

### 4. Executar o Projeto

O arquivo `src/main.py` Ã© o ponto de entrada do projeto. Ele inicia simultaneamente os seguintes componentes:

* O **Kafka Producer** (que gera e envia dados para o Kafka),
* O **Kafka Consumer** (que consome as mensagens e as envia para o MongoDB),
* A aplicaÃ§Ã£o **Streamlit** (que exibe o dashboard interativo).

Para executar o fluxo completo, basta rodar o script `main.py`:

```bash
python src/main.py
```

O script irÃ¡ iniciar os trÃªs processos em paralelo.

### 5. Acessar o Dashboard Streamlit

ApÃ³s iniciar o projeto com o comando acima, vocÃª poderÃ¡ acessar o dashboard no navegador atravÃ©s do endereÃ§o:

```bash
http://localhost:8501
```

---

## ğŸ§ª Testes

Os testes podem ser executados com o framework de testes de sua escolha. Um exemplo de teste jÃ¡ estÃ¡ implementado no arquivo `src/test/verifica_dados_mongo.py`, que verifica a persistÃªncia dos dados no MongoDB.

Para rodar os testes, vocÃª pode usar 2 estratÃ©gias:

* Utilizar o `pytest`:

```bash
PYTHONPATH=src poetry run pytest
```

* Executar a consulta direta via `python`:

```bash
poetry run python tests/verifica_dados_mongo.py
```

---

## Equipe de projeto:

- [Felipe Alves da Silva](https://github.com/felipealvss) (MatrÃ­cula: 2329032)
- [BenÃ­cio Bezerra de Abreu Carneiro](https://github.com/becarneiro) (MatrÃ­cula: 2419566-0)

---